{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T18:36:43.591214Z","iopub.execute_input":"2025-08-11T18:36:43.591995Z","iopub.status.idle":"2025-08-11T18:36:43.595981Z","shell.execute_reply.started":"2025-08-11T18:36:43.591962Z","shell.execute_reply":"2025-08-11T18:36:43.595175Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Kaggle environment setup & data listing","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T18:36:43.597161Z","iopub.execute_input":"2025-08-11T18:36:43.597454Z","iopub.status.idle":"2025-08-11T18:36:44.275733Z","shell.execute_reply.started":"2025-08-11T18:36:43.597429Z","shell.execute_reply":"2025-08-11T18:36:44.275158Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"niblabel librar\n","metadata":{}},{"cell_type":"markdown","source":"libraries\n","metadata":{}},{"cell_type":"code","source":"!pip install monai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T18:36:44.276905Z","iopub.execute_input":"2025-08-11T18:36:44.277155Z","iopub.status.idle":"2025-08-11T18:38:01.858379Z","shell.execute_reply.started":"2025-08-11T18:36:44.277132Z","shell.execute_reply":"2025-08-11T18:38:01.857446Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting monai\n  Downloading monai-1.5.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<3.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\nRequirement already satisfied: torch<2.7.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from monai) (2.6.0+cu124)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.24->monai) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7.0,>=2.4.1->monai)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7.0,>=2.4.1->monai) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7.0,>=2.4.1->monai) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7.0,>=2.4.1->monai) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.24->monai) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.24->monai) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.24->monai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.24->monai) (2024.2.0)\nDownloading monai-1.5.0-py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed monai-1.5.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":" Create data dictionary for BraTS 2020","metadata":{}},{"cell_type":"code","source":"from glob import glob\nimport os\n\nbase_path = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\nsubjects = sorted(os.listdir(base_path))\n\ndata_dicts = []\nfor sub in subjects:\n    sub_path = os.path.join(base_path, sub)\n    if os.path.isdir(sub_path):\n        data_dicts.append({\n            \"image\": [\n                os.path.join(sub_path, f\"{sub}_t1.nii\"),\n                os.path.join(sub_path, f\"{sub}_t1ce.nii\"),\n                os.path.join(sub_path, f\"{sub}_t2.nii\"),\n                os.path.join(sub_path, f\"{sub}_flair.nii\"),\n            ],\n            \"label\": os.path.join(sub_path, f\"{sub}_seg.nii\")\n        })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T18:38:01.859492Z","iopub.execute_input":"2025-08-11T18:38:01.859808Z","iopub.status.idle":"2025-08-11T18:38:02.077385Z","shell.execute_reply.started":"2025-08-11T18:38:01.859774Z","shell.execute_reply":"2025-08-11T18:38:02.076839Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Define preprocessing & augmentation pipeline","metadata":{}},{"cell_type":"code","source":"from monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Compose, ScaleIntensityRanged,\n    CropForegroundd, RandFlipd, RandShiftIntensityd,\n    EnsureTyped, Resized\n)\n\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),  \n    ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0.0, b_max=1.0, clip=True),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n    RandShiftIntensityd(keys=[\"image\"], offsets=0.10, prob=0.5),\n    Resized(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n    EnsureTyped(keys=[\"image\", \"label\"])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T18:38:02.079006Z","iopub.execute_input":"2025-08-11T18:38:02.079209Z"}},"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-08-11 18:38:19.539079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754937499.720285      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754937499.771504      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Build MONAI Dataset & DataLoader","metadata":{}},{"cell_type":"code","source":"from monai.data import Dataset, DataLoader\n\ntrain_ds = Dataset(data=data_dicts[:10], transform=train_transforms)  # use fewer samples to test\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the SwinUNETR model","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    print(\"Max label value:\", batch[\"label\"].max().item())\n    break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.networks.nets import SwinUNETR\nimport torch\n\ndevice = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(torch.__version__)\nprint(torch.version.cuda)\nprint(torch.cuda.is_available())\n\nmodel = SwinUNETR(\n    spatial_dims=3,\n    in_channels=4,     # 4 MRI modalities: T1, T1ce, T2, FLAIR\n    out_channels=5,    # For example: NCR/NET, ED, ET (segmentation labels)\n    feature_size=24,\n    use_checkpoint=False\n).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define loss, optimizer, and run 1 training step","metadata":{}},{"cell_type":"code","source":"from monai.losses import DiceLoss\nfrom torch.optim import Adam\n\nloss_function = DiceLoss(to_onehot_y=True, softmax=True)\noptimizer = Adam(model.parameters(), 1e-4)\n\nnum_epochs = 5  # example\ntrain_losses = []  # ✅ initialize here\nval_losses = []    # if you do validation\n\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss = 0\n    step = 0\n\n    for batch in train_loader:\n        inputs = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(inputs)\n        loss = loss_function(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        step += 1\n\n    avg_loss = epoch_loss / step\n    train_losses.append(avg_loss)  # ✅ won't cause NameError\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Validation transforms","metadata":{}},{"cell_type":"code","source":"val_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=0, a_max=255, b_min=0.0, b_max=1.0, clip=True),\n    CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n    Resized(keys=[\"image\", \"label\"], spatial_size=(128, 128, 64)),\n    EnsureTyped(keys=[\"image\", \"label\"])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Split dataset","metadata":{}},{"cell_type":"code","source":"train_data = data_dicts[:200]  # adjust as needed\nval_data = data_dicts[200:220]  # adjust for your test size\n\ntrain_ds = Dataset(data=train_data, transform=train_transforms)\nval_ds = Dataset(data=val_data, transform=val_transforms)\n\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.metrics import DiceMetric\nfrom monai.transforms import AsDiscrete\nfrom monai.data.utils import decollate_batch\n\n# Metrics\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\")\npost_pred = AsDiscrete(argmax=True, to_onehot=5)  # 5 classes\npost_label = AsDiscrete(to_onehot=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate(model, val_loader):\n    model.eval()\n    dice_metric.reset()\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            val_images = batch[\"image\"].to(device)\n            val_labels = batch[\"label\"].to(device)\n            \n            val_outputs = model(val_images)\n            \n            # Convert outputs & labels to one-hot\n            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n            \n            # Compute Dice\n            dice_metric(y_pred=val_outputs, y=val_labels)\n    \n    mean_dice = dice_metric.aggregate().item()\n    dice_metric.reset()\n    return mean_dice\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_epochs = 5  # change as needed\n\nfor epoch in range(max_epochs):\n    print(f\"Epoch {epoch+1}/{max_epochs}\")\n    epoch_loss = 0\n    step = 0\n    \n    # --- Training ---\n    model.train()\n    for batch in train_loader:\n        step += 1\n        inputs = batch[\"image\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        outputs = model(inputs)\n        loss = loss_function(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n    \n    avg_loss = epoch_loss / step\n    train_losses.append(avg_loss)\n\n    # --- Validation ---\n    val_dice = validate(model, val_loader)\n    val_dices.append(val_dice)\n\n    print(f\"Train Loss: {avg_loss:.4f} | Val Dice: {val_dice:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,4))\n\n# Loss plot\nplt.subplot(1,2,1)\nplt.plot(train_losses, label=\"Train Loss\", marker='o')\nplt.title(\"Training Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n# Dice score plot\nplt.subplot(1,2,2)\nplt.plot(val_dices, label=\"Val Dice\", color='orange', marker='o')\nplt.title(\"Validation Dice Score\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice Score\")\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}